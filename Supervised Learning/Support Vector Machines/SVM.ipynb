{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7094d84f",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N â€” the number of features) that distinctly classifies the data points.\n",
    "![alt](https://miro.medium.com/max/600/0*9jEWNXTAao7phK-5.png)\n",
    "To separate the two classes of data points, there are many possible hyperplanes that could be chosen. Our objective is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes. Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence.\n",
    "Hyperplanes are decision boundaries that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes. Also, the dimension of the hyperplane depends upon the number of features. If the number of input features is 2, then the hyperplane is just a line. If the number of input features is 3, then the hyperplane becomes a two-dimensional plane. It becomes difficult to imagine when the number of features exceeds 3.\n",
    "Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM.\n",
    "![alt](https://miro.medium.com/max/1400/0*ecA4Ls8kBYSM5nza.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe7474",
   "metadata": {},
   "source": [
    "Let us now try to implement what we have learned so far in python using scikit-learn. To make a support vector machine classifier, we will follow the following steps.\n",
    "\n",
    "- Loading the data\n",
    "\n",
    "- Exploring Data\n",
    "\n",
    "- Splitting Data\n",
    "\n",
    "- Generating The Model\n",
    "\n",
    "- Model Evaluation\n",
    "\n",
    "- Loading The Data\n",
    "\n",
    "We are using the cancer data-set in the sklearn library, we will make a classifier to predict whether the cancer is malignant or benign. We can load the data-set in the following manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0dc884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.245e+01 1.570e+01 8.257e+01 4.771e+02 1.278e-01 1.700e-01 1.578e-01\n",
      " 8.089e-02 2.087e-01 7.613e-02 3.345e-01 8.902e-01 2.217e+00 2.719e+01\n",
      " 7.510e-03 3.345e-02 3.672e-02 1.137e-02 2.165e-02 5.082e-03 1.547e+01\n",
      " 2.375e+01 1.034e+02 7.416e+02 1.791e-01 5.249e-01 5.355e-01 1.741e-01\n",
      " 3.985e-01 1.244e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    " \n",
    "cancer_data = datasets.load_breast_cancer()\n",
    "print(cancer_data.data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdc476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(cancer_data.data.shape)\n",
    "#target set\n",
    "print(cancer_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df44f3c5",
   "metadata": {},
   "source": [
    "In this, 0 represents malignant, and 1 represents benign.\n",
    "***  \n",
    "### Splitting Data\n",
    "\n",
    "We will divide the data-set into a training set and test set to get accurate results. After this, we will split the data using the train_test_split() function. We will need 3 parameters like in the example below. The features to train the model, the target, and the test set size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc16f3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "cancer_data = datasets.load_breast_cancer()\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data.data, cancer_data.target, test_size=0.4,random_state=109)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05d36f5",
   "metadata": {},
   "source": [
    "### Generating The Model\n",
    "\n",
    "To generate the model, we will first import the SVM module from sklearn to create a support vector classifier in svc() by passing the argument kernel as the linear kernel.\n",
    "\n",
    "Then we will train the data-set using the set() and make predictions using the predict() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e247a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "#create a classifier\n",
    "cls = svm.SVC(kernel=\"linear\")\n",
    "#train the model\n",
    "cls.fit(X_train,y_train)\n",
    "#predict the response\n",
    "pred = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16791dba",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "With this, we can predict how accurately the model or classifier can predict if the patient has heart disease or not. So we will calculate the accuracy score, recall, and precision for our evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a32c786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracy: 0.9649122807017544\n",
      "precision: 0.9642857142857143\n",
      "recall 0.9782608695652174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96        90\n",
      "           1       0.96      0.98      0.97       138\n",
      "\n",
      "    accuracy                           0.96       228\n",
      "   macro avg       0.97      0.96      0.96       228\n",
      "weighted avg       0.96      0.96      0.96       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#accuracy\n",
    "print(\"acuracy:\", metrics.accuracy_score(y_test,y_pred=pred))\n",
    "#precision score\n",
    "print(\"precision:\", metrics.precision_score(y_test,y_pred=pred))\n",
    "#recall score\n",
    "print(\"recall\" , metrics.recall_score(y_test,y_pred=pred))\n",
    "print(metrics.classification_report(y_test, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e61dfa8",
   "metadata": {},
   "source": [
    "We are getting the accuracy, precision and recall values as 0.96, 0.96 and 0.97 which is highly unlikely. Since our data-set was quite descriptive and decisive we were able to get such accurate results. Normally, anything above a 0.7 accuracy score is a good score.\n",
    "\n",
    "Let us take a look at another example to understand how we can use the Support Vector Machine classification algorithm in a different way.\n",
    "***\n",
    "### Character Recognition With Support Vector Machine\n",
    "\n",
    "In this example, we will use the existing digit data set and train the classifier. After this, we will use the classifier to predict a digit and plot the image to be more distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0693a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 ... 5 7 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "#loading the dataset\n",
    "letters = datasets.load_digits()\n",
    "#generating the classifier\n",
    "clf = svm.SVC(gamma=0.001, C=100)\n",
    "#training the classifier\n",
    "X,y = letters.data[:-10], letters.target[:-10]\n",
    "clf.fit(X,y)\n",
    "#predicting the output \n",
    "print(clf.predict(letters.data[:-10]))\n",
    "plt.imshow(letters.images[6], interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500dde35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

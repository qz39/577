## Decision/ Regression Trees  
Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.

Decision trees tend to be the method of choice for predictive modeling because they are relatively easy to understand and are also very effective. The basic goal of a decision tree is to split a population of data into smaller segments. There are two stages to prediction. The first stage is training the model—this is where the tree is built, tested, and optimized by using an existing collection of data. In the second stage, you actually use the model to predict an unknown outcome.

Decision trees are constructed from only two elements — nodes and branches.  
![alt](https://miro.medium.com/max/1400/1*E2br87UjCErSE2eqJ56DWQ.png)
## Datasets  
- make circles from scikit learn  
Make a large circle containing a smaller circle in 2d.  
A simple toy dataset to visualize clustering and classification algorithms.  
https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html?highlight=make%20circles#sklearn.datasets.make_circles

- Boston housing dataset  
The boston housing dataset provides the median Boston house-price data by Harrison, D. and Rubinfeld, D.L. It has 1 numeric target labels, and the total sample size is 506 without missing value. There're 13 features and there're all numeric, real, and positive.
